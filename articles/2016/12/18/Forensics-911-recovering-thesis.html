<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Forensics 911 - recovering a thesis of one year work</title>
  <meta name="description" content="⊕  Trimming and ScrapingA friend of mine called me: a girl friend of him was hopeless trying to recover her thesis from a corrupted usb stick three days befo...">

  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  

  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX","output/HTML-CSS"],
        tex2jax: {inlineMath: [["$$","$$"],["\\(","\\)"]]},
	TeX: {
	  Macros: {
            
	  }
	}
      });
    </script>
    
      <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js' async></script>
    
  

  
    <script
       src="https://code.jquery.com/jquery-3.4.1.min.js"
       integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
       crossorigin="anonymous"></script>
  

  

    
      <script src='https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js' ></script>
    

    
      <script src="https://d3js.org/d3.v4.min.js"></script>
    

    <script src='/book-of-gehn/js/venn/venn.min.js'></script>
    <script src='/book-of-gehn/js/venn/helper.js'></script>

    <script src='/book-of-gehn/js/fix_syntax_highlight.js'></script>
  <link rel="stylesheet" type="text/css" href="/book-of-gehn/css/tufte.css">
  <link rel="stylesheet" type="text/css" href="/book-of-gehn/css/latex.css">

  <link rel="canonical" href="/book-of-gehn/articles/2016/12/18/Forensics-911-recovering-thesis.html">

  <link rel="stylesheet" type="text/css" href="/book-of-gehn/css/all.min.css">

  <link type="application/atom+xml" rel="alternate" href="/book-of-gehn/feed.xml" title="The Book of Gehn" />
</head>

  <body>
    <header>
	
		<h1 class="header-title"><a href="/book-of-gehn/">The Book of Gehn</a></h1>
		
		
	

    

    
</header>

    <article class="group">
      <h1>Forensics 911 - recovering a thesis of one year work</h1>
<p class="subtitle">December 18, 2016</p>

<p><label for="mf-5d444facb38e79ef0c8ab5be26ebb333" class="margin-toggle  in-index-only">⊕</label><input type="checkbox" id="mf-5d444facb38e79ef0c8ab5be26ebb333" class="margin-toggle  in-index-only" /><span class="marginnote  in-index-only"><img style="" class="fullwidth" alt="Trimming and Scraping" src="/book-of-gehn/assets/trimming_scraping_ddrescue.png" />  <br />Trimming and Scraping</span></p>

<p>A friend of mine called me: a girl friend of him was hopeless trying to recover her thesis from a corrupted usb stick <em>three days</em> before her presentation.</p>

<p>She was working in her thesis for almost a year, saving all the progresses in that usb stick. But what she didn’t know was that an usb memory has a limited number of writes and with more writes eventually the file system gets corrupted.</p>

<p>This is the real story behind a forensics rally trying to recover her one year work.<!--more--></p>

<p><em>“Ok”</em> – I said to my friend – <em>“bring me the pendrive. Tell to this girl that she must unplug it to avoid any further corruption. She mustn’t to touch anything…”</em></p>

<p><em>“Well, I can’t give you the pendrive right now”</em> – he said – <em>“She gave it to his father to see if he could recover the file. He couldn’t. She also asked to a friend of hers who also couldn’t and I think that she took it to a guy that works with these things.”</em></p>

<p><strong>Rule number one:</strong> don’t touch it, it will only get worse. Obviously this wasn’t the case.</p>

<h2 id="why-dd-is-not-the-best-option-for-cloning-a-disk">Why <code class="highlighter-rouge">dd</code> is not the best option for cloning a disk</h2>

<p>It was 11 pm and the pen drive was at last in my hands: <em>it’s forensic time</em></p>

<p>First that all we need an image of the disk to work with it without worrying to damage the original usb with our tests.</p>

<p>There are quite a few options out there, and <code class="highlighter-rouge">dd</code> is the first choice that crossed my mind but not the best.</p>

<p><code class="highlighter-rouge">dd</code> can be found in any linux box by default. It can copy the disk to a file reading one block of data at time and avoiding mounting the file system at all.</p>

<p>The disk can only be read and written in terms of sectors which in general have a 512 bytes of size. Because of that it is desired to set the size of the blocks of <code class="highlighter-rouge">dd</code> for reading and writing to a multiple of the sector size.</p>

<p>Using a different value, it will result in reading and writing incomplete sectors: it will work but you will need at least a second disk access to complete the same sector so it’s a complete waste of time.</p>

<p><strong>Rule number two:</strong> the sector size is a key parameter. Some tools will work better with it, others will don’t work at all without it. Always check this size.</p>

<p>Lets check that with <code class="highlighter-rouge">fdisk</code></p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> fdisk <span class="nt">-l</span> /dev/sdc
<span class="go">Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
</span></code></pre></div></div>

<p>So, why we should change the size of the block used by <code class="highlighter-rouge">dd</code> anyway? Well, larger blocks may improve the performance accessing less times to the disk. But it also can be a disadvantage.</p>

<p><code class="highlighter-rouge">dd</code> will <strong>stop</strong> if a read fails. Even if <code class="highlighter-rouge">dd</code> goes on, the whole failed block is discarded and skipped. That means that a single bad sector of just 512 bytes can make that the whole block of, lets say 2k, gets discarded. 
Worse, <code class="highlighter-rouge">dd</code> will <em>skip</em> the failed block meaning that he won’t write anything to the output, leading to a shorter image.
And most of the forensic tools don’t like these kind of images.</p>

<p>So we need to make sure that <code class="highlighter-rouge">dd</code> will not stop and at least write something in replace of a failed block.</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> <span class="nb">dd </span><span class="k">if</span><span class="o">=</span>/dev/sdc <span class="nv">of</span><span class="o">=</span>sdc.dd <span class="nv">bs</span><span class="o">=</span>2k <span class="nv">conv</span><span class="o">=</span>noerror,sync
</code></pre></div></div>

<p>Those two flags in the <code class="highlighter-rouge">conv</code> parameter do the magic:</p>

<ul>
  <li><code class="highlighter-rouge">noerror</code> will force to continue the copy even if there is a reading error.</li>
  <li><code class="highlighter-rouge">sync</code> will replace a failed block by a block full of zeros in the output.</li>
</ul>

<p>If <code class="highlighter-rouge">dd</code> is new to you, the other parameters are:</p>

<ul>
  <li><code class="highlighter-rouge">if</code> is the name of the file or device to read, <code class="highlighter-rouge">/dev/sdc</code> was the pendrive in this case</li>
  <li><code class="highlighter-rouge">of</code> the same but to write, <code class="highlighter-rouge">sdc.dd</code> is the name of disk image</li>
  <li><code class="highlighter-rouge">bs</code> the block size, 2k in this case.</li>
</ul>

<p>But as I said before, <code class="highlighter-rouge">dd</code> is not the best choice. Think in the above setting, <code class="highlighter-rouge">bs=2k</code> means blocks of 2k of size. With only one single bad sector the whole 2k bytes block is lost.</p>

<p>Don’t get me wrong, <code class="highlighter-rouge">dd</code> is not a bad software but it was never been designed for forensics purposes.</p>

<h2 id="cloning-the-disk-with-gnu-ddrescue">Cloning the disk with <code class="highlighter-rouge">GNU ddrescue</code></h2>

<p>There are a lot of tools for recovering out there, some are based in <code class="highlighter-rouge">dd</code>, other don’t. I found quite useful the tool <code class="highlighter-rouge">GNU ddrescue</code> which despite the name it’s not based in <code class="highlighter-rouge">dd</code> at all.</p>

<p>Watch out there, there is also a tool called <code class="highlighter-rouge">dd_rescue</code> (notice the underscore) that has nothing to do with <code class="highlighter-rouge">GNU ddrescue</code>.</p>

<p><code class="highlighter-rouge">GNU ddrescue</code>, from now on just <code class="highlighter-rouge">ddrescue</code>, will copy a disk through three stages.</p>

<p>In the first, it reads blocks of data and copy them to the output in the same manner that <code class="highlighter-rouge">dd</code> but unlike the latter, <code class="highlighter-rouge">ddrescue</code> will not stop if it found an error nor will put zeros nor discard the block if the reading fails.</p>

<p><label for="mf-5d444facb38e79ef0c8ab5be26ebb333" class="margin-toggle ">⊕</label><input type="checkbox" id="mf-5d444facb38e79ef0c8ab5be26ebb333" class="margin-toggle " /><span class="marginnote "><img class="fullwidth" alt="Trimming and Scraping" src="/book-of-gehn/assets/trimming_scraping_ddrescue.png" />  <br />Trimming and Scraping</span></p>

<p>Instead, it will <em>keep track</em> of all the failed blocks in a log file.</p>

<p>In the second phase, it will try to read again <em>only</em> the failed blocks, but this time will read sector by sector from the begin of the block until it reaches a bad sector and then it will do the same but starting from the end and going backwards. This is called <em>trimming</em> the block.</p>

<p>In the third and last phase, it will try to read all the remained trimmed blocks again, sector by sector, but without stopping at the first bad sector. Every single sector will be tried. This is called <em>scraping</em> the block.</p>

<p>What is the output of all this process? An image of the disk with holes in it representing the missing bad sectors and the log file which keeps track of those holes.</p>

<p>Here there are the lines of code:</p>

<p>For the first phase</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> ddrescue <span class="nt">--no-trim</span> <span class="nt">--no-scrape</span> /dev/sdc sdc.img sdc.ddrescue.logfile
</code></pre></div></div>

<p>And for the second and third phases</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> ddrescue <span class="nt">-r3</span> /dev/sdc sdc.img sdc.ddrescue.logfile
</code></pre></div></div>

<p>Just for the record, the flags are:</p>

<ul>
  <li><code class="highlighter-rouge">no-trim</code> disables the second phase</li>
  <li><code class="highlighter-rouge">no-scrape</code> disables the third phase</li>
  <li><code class="highlighter-rouge">r3</code> retries each bad sector at most three times</li>
</ul>

<p>By default, <code class="highlighter-rouge">ddrescue</code> performs the three phases at once so, why I separated the first phase from the rest two?</p>

<p>The first will give you a first approximation probably with all the data that you need.</p>

<p>If the disk has a lot of bad sectors, <code class="highlighter-rouge">ddrescue</code> will spend a lot of time trying to recover the data in the second and third phases. When the disk has several gigabytes of size this will take a longer time (boring!). The first phase gives you a trade off between to get a result <em>faster but incomplete</em>.</p>

<p>The rest two phases will try to complete the image and sometimes those little chunks of data recovered will be the missing pieces of the puzzle so it is worth to try those phases too.</p>

<p><strong>Rule number three:</strong> try to get an incomplete piece of data to work on as soon as possible while you get the complete picture in background.</p>

<p>In this point I prefer to take a copy of the image and the log file before doing anything else. Hashing is also a good practice so you can corroborate in the future if the image was altered. A sha1 should be enough.</p>

<p>The image will have holes, one for each bad sector that couldn’t be recovered. Because most of the tools cannot work with images with holes we need to fill those with a custom string.</p>

<p>Some people fill them with zeros but I found that filling them with a cookie or special string is more useful. You can later use <code class="highlighter-rouge">grep</code> to search for the cookie to see which files were corrupted.</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> <span class="nb">echo</span> <span class="nt">-n</span> <span class="s2">"BADxSEC!"</span> <span class="o">&gt;</span> badsec_mark
<span class="gp">$</span> ddrescue <span class="nt">--fill-mode</span><span class="o">=</span>- badsec_mark sdc.img sdc.ddrescue.logfile
</code></pre></div></div>

<h2 id="mounting">Mounting</h2>

<p>To this point what we did was a clone of the entire disk, including the partition table so the next thing that we need is to check if the partition table is ok. It is important to check each value to see if it makes sense, <em>don’t trust in the output</em> of a magical tool, use your own brain. Remember that you are reading corrupted data.</p>

<p><strong>Rule number four:</strong> don’t trust in anyone.</p>

<p>To see if the partition table is ok I used the <code class="highlighter-rouge">mmls</code> tool from the <code class="highlighter-rouge">sleuthkit</code> package.</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> mmls <span class="nt">-B</span> sdc.img
<span class="go">DOS Partition Table
Offset Sector: 0
Units are in 512-byte sectors

      Slot      Start        End          Length       Description
</span><span class="gp">000:  Meta      0000000000   0000000000   0000000001   Primary Table (#</span>0<span class="o">)</span>
<span class="go">001:  -------   0000000000   0000002063   0000002064   Unallocated
002:  000:000   0000002064   0008376319   0008374256   Win95 FAT32 (0x0b)
</span></code></pre></div></div>

<p>This looks good, the first sector is designated to the partition table and the disk has only one FAT32 partition.</p>

<p>The lengths are in sector terms so to know the size of the partition in bytes we can just do (8374256 * 512.0) / (1024 ** 3) which yields 3.99 gigabytes which it makes sense given that the usb stick is of 4 gigabytes.</p>

<p>The output of <code class="highlighter-rouge">mmls</code> can be a little confusing because it is showing that the first and the second slices start both at the 0 position. So those two slices overlaps and that is wrong and could mean that the partition table is corrupt but it is not.</p>

<p><code class="highlighter-rouge">mmls</code> can show you four things at the same time:</p>

<ul>
  <li>the allocated (<code class="highlighter-rouge">-a</code>) and unallocated (<code class="highlighter-rouge">-A</code>) spaces</li>
  <li>the metadata (<code class="highlighter-rouge">-m</code>) and the non-metadata (<code class="highlighter-rouge">-M</code>) volumes</li>
</ul>

<p>If you don’t use any of those flags, <code class="highlighter-rouge">mmls</code> will show all the spaces and volumes and the concept of space and volume can overlap. To see if there is a real overlapping or not, we can see the allocated and unallocated spaces only:</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> mmls <span class="nt">-a</span> <span class="nt">-A</span> sdb.img
<span class="go">DOS Partition Table
Offset Sector: 0
Units are in 512-byte sectors

      Slot      Start        End          Length       Description
001:  -------   0000000000   0000002063   0000002064   Unallocated
002:  000:000   0000002064   0008376319   0008374256   Win95 FAT32 (0x0b)
</span></code></pre></div></div>

<p>And as you can see the spaces start and end at the correct position without overlapping. So this seems to be ok.</p>

<p>Let’s try to mount that file system:</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> mount <span class="nt">-o</span> ro,loop,offset<span class="o">=</span>1056768 sdc.img mnt/
</code></pre></div></div>

<p>Because the file system doesn’t start at the begin of the image file we need to calculate the offset where it really starts: start sector (2064) multiplied by the sector size (512) or just 2064 * 512 = 1056768.</p>

<p>The mount didn’t fail so at least the file system is not <em>so</em> damaged.</p>

<h2 id="trying-to-recover-the-thesis-politely">Trying to recover the thesis politely</h2>

<p>Let’s see if any file’s data are corrupt</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> <span class="nb">grep</span> <span class="nt">-R</span> <span class="s2">"BADxSEC!"</span> <span class="k">*</span>
</code></pre></div></div>

<p>None file seems to be corrupt. Of course, <code class="highlighter-rouge">grep</code> is not telling you the whole story.</p>

<p>The file system doesn’t see a file as a single unit but as a serie of small blocks of data chained. Those chains are stored and can be corrupted too. If that happen the files can be missing, truncated, merged, or who-knows-what-else because the file system cannot ensemble the file from the blocks.</p>

<p>Nevertheless, looking in the mounted file system, the thesis.docx was there, so we can try to recover it directly. It’s a docx file (a zip file) so we can try:</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> zip <span class="nt">-FF</span> thesis.docx <span class="nt">--out</span> thesis.recovered.docx
</code></pre></div></div>

<p>But it didn’t work, only a few pages were recovered.</p>

<h2 id="recovering-the-thesis-by-bad">Recovering the thesis by bad</h2>

<p>Trying to fix a damaged file system is not a trivial task but before even thinking about that, we may have some luck looking for an old deleted backup or a temporary file.</p>

<p>When a file is deleted the file system will remove the link between the file and the rest of the system preventing that anyone can access it again. The space is marked as free and ready to be used by others but is not <em>erased</em>, so the data is still there, inaccessible from the file system, but there.</p>

<p>We can recover those deleted files easily scanning the whole image instead of using the mounted file system.</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> foremost <span class="nt">-t</span> zip sdc.img
</code></pre></div></div>

<p>For the curious:</p>

<ul>
  <li><code class="highlighter-rouge">-t zip</code> will try to extract all the zip like files including docx ones. <code class="highlighter-rouge">foremost</code> has a <code class="highlighter-rouge">-t doc</code> flag but it will not work with docx files</li>
</ul>

<p>The result? 41 files recovered. Cool! but it is 3 am of the early morning and checking one file at a time is not the best way to spend the night.</p>

<p>Is there any way to filter them to check only a few of them?</p>

<p><strong>Rule number five:</strong> sleep. If you need to think out of the box, you had better to be rested.</p>

<p>It’s 9 am, I have a strategy and the round two begins. <em>Fight!</em></p>

<p>Most of the files, including the docx files, have metadata so I thought, “maybe I can filter the files using somes attribute in the metadata”.</p>

<p>For that we can use a tool from the <code class="highlighter-rouge">libimage-exiftool-perl</code> package</p>

<div class="language-shell_session highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp">$</span> exiftool  <span class="k">*</span>.docx | <span class="nb">grep</span> <span class="s2">"========</span><span class="se">\|</span><span class="s2">File Name</span><span class="se">\|</span><span class="s2">Heading</span><span class="se">\|</span><span class="s2">Title</span><span class="se">\|</span><span class="s2">Pages"</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">exiftool</code> will extract all the metadata that it can. It’s a very complex tool with a lot of flags and options and  is out of scope for this post to explain.</p>

<p>I was expecting that some of the documents have a clue in their titles or heading but it was the amount of pages what I used as a hint. From all those documents only three had more than 50 pages.</p>

<p>Those were three non-corrupted older versions of the thesis. In fact, one of them was only one old week.</p>

<p>It’s 10 am we recovered the thesis.</p>

<p><strong>Rule number six:</strong> next time, do a backup.</p>




    </article>
    <span class="print-footer">Forensics 911 - recovering a thesis of one year work - December 18, 2016 - Gehn</span>
    <footer>
    <hr class="slender">
    <div class="credits">
        <span>&copy; 2021
            
            Gehn
        </span></br>
            <a style="text-decoration: none;" href="/book-of-gehn/feed.xml"><img height="16px" width="16px" src="/book-of-gehn/assets/blog-assets/rss-32px.png" /></a>
        <br>
        

    
    </div>
</footer>

  </body>
</html>
