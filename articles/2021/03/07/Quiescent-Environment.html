<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Quiescent Environment</title>
  <meta name="description" content="You are working in optimizing a piece of software to reducethe CPU cycles that it takes.To compare your improvements, it is reasonable to measure the elapsed...">

  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  

  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js"],
        jax: ["input/TeX","output/HTML-CSS"],
        tex2jax: {inlineMath: [["$$","$$"],["\\(","\\)"]]},
	TeX: {
	  Macros: {
            
	  }
	}
      });
    </script>
    
      <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js' async></script>
    
  

  
    <script
       src="https://code.jquery.com/jquery-3.4.1.min.js"
       integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
       crossorigin="anonymous"></script>
  

  

    
      <script src='https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.9.1/underscore-min.js' ></script>
    

    
      <script src="https://d3js.org/d3.v4.min.js"></script>
    

    <script src='/book-of-gehn/js/venn/venn.min.js'></script>
    <script src='/book-of-gehn/js/venn/helper.js'></script>

    <script src='/book-of-gehn/js/fix_syntax_highlight.js'></script>
  <link rel="stylesheet" type="text/css" href="/book-of-gehn/css/tufte.css">
  <link rel="stylesheet" type="text/css" href="/book-of-gehn/css/latex.css">

  <link rel="canonical" href="/book-of-gehn/articles/2021/03/07/Quiescent-Environment.html">

  <link rel="stylesheet" type="text/css" href="/book-of-gehn/css/all.min.css">

  <link type="application/atom+xml" rel="alternate" href="/book-of-gehn/feed.xml" title="The Book of Gehn" />
</head>

  <body>
    <header>
	
		<h1 class="header-title"><a href="/book-of-gehn/">The Book of Gehn</a></h1>
		
		
	

    

    
</header>

    <article class="group">
      <h1>Quiescent Environment</h1>
<p class="subtitle">March 7, 2021</p>

<p>You are working in optimizing a piece of software to reduce
the CPU cycles that it takes.</p>

<p>To compare your improvements, it is reasonable to measure the elapsed
time before and after your change.</p>

<p>Unless you are using a simulator, it is impossible to run a program
<em>isolated</em> from the rest and your measurements will be noisy.</p>

<p>If you want to take precise measurements you need a <em>quiescent</em>
environment as much as possible.<!--more--></p>

<h2 id="an-incomplete-cheatsheet">An incomplete cheatsheet</h2>

<p>Isolate the machine:</p>
<ul>
  <li>use a bare metal machine or VMs if not possible. Try to
avoid container environments.</li>
  <li>unplug the network cable or reduce by some mean the traffic (from
outside the machine)</li>
</ul>

<p>At hardware level disable:</p>
<ul>
  <li>Hyperthreading (hardware multitenancy)</li>
  <li>Intel Turbo Boost or Overclocking <a href="https://askubuntu.com/questions/619875/disabling-intel-turbo-boost-in-ubuntu">How-to (maybe)</a></li>
  <li>Dynamic Voltage &amp; Frequency Scaling <a href="https://askubuntu.com/questions/523640/how-i-can-disable-cpu-frequency-scaling-and-set-the-system-to-performance">How-to (maybe)</a></li>
</ul>

<p>At the kernel level:</p>
<ul>
  <li>isolate one or more CPUs so you run your programs there without much
interruptions from other tasks. Two options: removing the CPUs from the
scheduler at boottime <a href="https://www.kernel.org/doc/html/v4.19/admin-guide/kernel-parameters.html?highlight=isolcpu">(isolcpus)</a>
or assigning them to an isolated cgroup at runtime
<a href="https://manpages.ubuntu.com/manpages/bionic/man1/cset.1.html">(cset)</a>.</li>
  <li>use a preconfigured
<a href="https://manpages.debian.org/buster/tuned/tuned.8.en.html">tuned</a> setup.
<a href="https://github.com/redhat-performance/tuned/blob/master/profiles/realtime/tuned.conf">(repo)</a>;
<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/chap-Realtime-Specific_Tuning">(guide)</a>.</li>
  <li>disable the interruptions handling in those CPUs.</li>
  <li>use thread’s CPU affinity to assign the threads to each CPU (this is
mandatory if you disabled the scheduler with <code class="highlighter-rouge">isolcpus</code>). See
<a href="https://man7.org/linux/man-pages/man1/taskset.1.html">taskset</a></li>
  <li>disable not needed kernel threads ? <a href="https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt">may
be</a>; and
other sources of noise. See <a href="https://lwn.net/Articles/816298/">more</a></li>
</ul>

<p>At the user-space level:</p>
<ul>
  <li>disable all the services that you can</li>
  <li>follow some part of the
<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/chap-general_system_tuning">general</a>
and
<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/chap-Realtime-Specific_Tuning">advanced</a>
tuning guides.</li>
</ul>

<p>At the instrumentation level:</p>
<ul>
  <li>static low-overhead instrumentation if possible, dynamic if you can’t
recompile.</li>
  <li>prefer deterministic (like counting the elapsed time) over sampling, specially for
small-fast function targets; sometimes sampling is the only way however.</li>
  <li>use a <a href="/book-of-gehn/articles/2021/02/27/High-Precision-Timers.html">high precision clock</a>.</li>
  <li>perhaps a <a href="https://github.com/plasma-umass/coz">causal profiler
(coz)</a>. See
<a href="https://easyperf.net/blog/2020/02/26/coz-vs-sampling-profilers">post</a>
and <a href="https://www.youtube.com/watch?v=r-TLSBdHe1A">video</a>.</li>
</ul>

<p>At the binary level:</p>
<ul>
  <li>code alignment can be mostly controlled by the compiler, but it may
add delays due the increasing of the binary. See
<a href="https://easyperf.net/blog/2018/01/25/Code_alignment_options_in_llvm">post</a>.</li>
  <li>if you cannot control it, randomize it: you will add noise but it
will be random noise and not <em>biased noise</em> which is much worst.
<a href="https://github.com/ccurtsinger/stabilizer">Stabilizer (may be)</a></li>
</ul>

<p>The experiment:</p>
<ul>
  <li>automate the setup of the machine as much as possible</li>
  <li>automate the experiment execution so it can be reproduced again in
the future.</li>
  <li>run several executions and track the minimum value (if applies); if
possible, try to run several different benchmark programs that use your
target function.</li>
  <li>use different test suites and benchmarks (<a href="https://github.com/google/benchmark">google’s</a>).</li>
</ul>

<h2 id="sources-of-noise-in-the-environment">Sources of noise in the environment</h2>

<p>There are a lot.</p>

<p>Other processes running, the OS scheduler making your program to <em>yield</em>
the CPU, the OS interrupting to process a more urgent task (like
interruptions) and more.</p>

<p>Graphical interfaces, network traffic and disk usage add to the mix.</p>

<figure class="fullwidth"><img src="/book-of-gehn/assets/timing-assets/all-services-up-and-down.svg" /><figcaption>The elapsed time of `foo()` executed 1000 times and sorted
from the smallest value to the largest. The last 10 values were drop
(not shown); numbers are in nanoseconds. On the left the experiment
was done in a machine without any modification; on the right all the
services were turned off, the CPU were isolated and the IRQ where
disabled. Note not only how smaller values are obtained in the
right environment (less noisy) but also the dispersion of the numbers
is smaller: on the left the time goes from 0.765 to 0.8 ns (range of 0.035 ns)
while on the right the time goes from 0.7635 to 0.7665 ns (range of
0.003 ns). One order of magnitude.</figcaption></figure>

<p>But software is not the only source of noise.</p>

<p>The CPU may decide to <em>slowdown</em> to conserve energy/reduce the power
consumption. This is called <a href="https://en.wikipedia.org/wiki/Dynamic_frequency_scaling">Dynamic Voltage &amp; Frequency Scaling
(DVFS)</a></p>

<p>On the other hand, the CPU may <em>speedup</em> and run faster if it see that
other CPUs are idle (basically the energy/power not used by the idle CPUs
is used by the busy CPU increasing the frequency). This is called
<a href="https://en.wikipedia.org/wiki/Overclocking">Dynamic Overclocking</a>
or in Intel parlance, <a href="https://en.wikipedia.org/wiki/Intel_Turbo_Boost">Turbo Boost</a></p>

<h2 id="multitenancy-illusion-of-power">Multitenancy: illusion of power</h2>

<p>Is you hardware fully dedicated to you and your programs?</p>

<p>In these days you need to take into account the virtualization:
how your OS interacts with the hypervisor
(if you are running in a VM like in AWS) and how many other VMs are
running in the same <em>bare metal</em>, competing for it.</p>

<p>And VMs are not the only ones that add overheads. If you are in
container like if you are using docker, you have the same issue.</p>

<p>This is called <a href="https://en.wikipedia.org/wiki/Multitenancy">multitenancy</a>.</p>

<p>A similar illusion of power can come from the hardware. Intel’s
<a href="https://en.wikipedia.org/wiki/Hyper-threading">Hyperthreading</a>
technology allows a CPU (a core) to run two threads
concurrently.</p>

<p>While having each thread it own set of registers in the CPU, the
hardware is <em>not</em> duplicated (you <em>don’t</em> have two cores).</p>

<p>Instead, hardware units like the ALU is shared among the hyper threads.
While the OS may show a CPU with 2 hyperthreads as 2 different cores,
the performance is only 15%-30% compared to a non-hyperthreaded CPU.</p>

<p>This is another form of multitenancy, a hardware-based multitenancy if
you want.</p>

<h2 id="noise-of-the-measurement">Noise of the measurement</h2>

<p>If you use a dynamic instrumentation like <a href="https://valgrind.org/">Valgrind</a>,
the code will <a href="https://valgrind.org/info/about.html">slowdown</a>
by a factor in range from 5 to 100.</p>

<p>A static instrumentation is faster but requires recompilation: you may
need to add code by hand or let the compiler to do it.</p>

<p>And it is not trivial. Consider the following code:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">void</span> <span class="nf">experiment</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">setup</span><span class="p">();</span>

    <span class="kt">uint64_t</span> <span class="n">begin</span> <span class="o">=</span> <span class="n">now</span><span class="p">();</span>
    <span class="n">foo</span><span class="p">();</span>
    <span class="kt">uint64_t</span> <span class="n">end</span> <span class="o">=</span> <span class="n">now</span><span class="p">();</span>

    <span class="n">tear_down</span><span class="p">();</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Elapsed %lu</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">end</span><span class="o">-</span><span class="n">begin</span><span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div>

<p>‘If <code class="highlighter-rouge">foo()</code> is <em>inlined</em>, the compiler / CPU may decide to execute
some instructions from <code class="highlighter-rouge">foo()</code> <em>before</em> taking the <code class="highlighter-rouge">begin</code> mark (or
<em>after</em> the <code class="highlighter-rouge">end</code> mark).</p>

<p>Even if <code class="highlighter-rouge">foo()</code> is not inline, code <em>before</em> the <code class="highlighter-rouge">begin</code> may be
executed <em>after</em> it (and the same for the <code class="highlighter-rouge">end</code> mark).</p>

<p><label for="mn-8deee7756f840e019fa18f4da18cddad" class="margin-toggle"> ⊕</label><input type="checkbox" id="mn-8deee7756f840e019fa18f4da18cddad" class="margin-toggle" /><span class="marginnote">I wrote a few posts about this: a lock free queue <a href="/book-of-gehn/articles/2020/03/22/Lock-Free-Queue-Part-I.html">part
1</a>,
<a href="/book-of-gehn/articles/2020/04/28/Lock-Free-Queue-Part-II.html">part
2</a>.
 </span></p>

<p>Welcome to the <em>out of order execution</em> world.</p>

<p>You could use barriers but these are <strong>not</strong> cheap.</p>

<h2 id="precision-of-the-measurement">Precision of the measurement</h2>

<p>Getting the time is not cost-free. Even the most <a href="/book-of-gehn/articles/2021/02/27/High-Precision-Timers.html">precise
clocks</a> like
<code class="highlighter-rouge">clock_gettime</code> adds some delay.</p>

<p>If instrumenting the binary (statically or dynamically) is too invasive,
sampling is another option like <a href="https://perf.wiki.kernel.org/index.php/Main_Page">linux’s perf</a>
(see <a href="http://www.brendangregg.com/perf.html">more</a>.</p>

<p>You just ask what function is a program running a few times per second
and count how many times a particular function was seen.</p>

<p>More times a function was seen, more <em>expensive</em> should be because it
was found more times in the CPU.</p>

<p>But it is tricky. What if the function is <em>called</em> a lot of times? That
would increase the probability of find it in the CPU too and it is not
necessary related with its performance.</p>

<p>And if you want to see the performance of a very small-quick function,
how many times do you need to sample the CPU until find the function
there? Unlikely, short events are mostly invisible for sampling tools.</p>

<p>This is the trade-off between <em>deterministic</em> and <em>sampling</em> profilers.</p>

<h2 id="unknown-variables">Unknown variables</h2>

<p>This is perhaps the most subtle topic.</p>

<p>You have the first version of <code class="highlighter-rouge">foo()</code>, let’s name it <code class="highlighter-rouge">foo_1()</code>. By some
mean you measure its performance in the most precise way and you
obtained <code class="highlighter-rouge">X</code>.</p>

<p>How do you know that <code class="highlighter-rouge">X</code> is real and not the product from an <em>unknown</em>
source of noise?</p>

<p>You don’t and you can probably assume that <code class="highlighter-rouge">X</code> <strong>is</strong>, in some part,
contributed by unknown sources of noise.</p>

<p>Assuming <em>additive</em> noise you can approximate the real value <code class="highlighter-rouge">X</code>
measuring <code class="highlighter-rouge">foo_1()</code> several times and getting the minimum.</p>

<p>Now that you “know” the performance of <code class="highlighter-rouge">foo_1()</code> you want to improve it.</p>

<p>You have <code class="highlighter-rouge">foo_2()</code>, you measure it several times, get the minimum and
obtain the approximated value of <code class="highlighter-rouge">Y</code>.</p>

<p>If you find <code class="highlighter-rouge">X &gt; Y</code> you may get happy: you improved <code class="highlighter-rouge">foo()</code>, <strong>didn’t
you?</strong></p>

<p>The fact that the improvement may <strong>not</strong> due your modification to
<code class="highlighter-rouge">foo()</code> but due the fact you did <strong>any</strong> modification.</p>

<p>Changing the code changes how the code is loaded in the memory.</p>

<p>A simple refactor moving two functions closer in the same file may
result in a better performance.</p>

<p>Consider the following two versions of the same <code class="highlighter-rouge">.c</code> file:</p>

<div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// version A            // version B</span>
<span class="kt">void</span> <span class="nf">foo</span><span class="p">()</span> <span class="p">{</span>            <span class="kt">void</span> <span class="n">foo</span><span class="p">()</span> <span class="p">{</span>
   <span class="c1">// code...              // code...</span>
   <span class="n">bar</span><span class="p">()</span>                   <span class="n">bar</span><span class="p">()</span>
<span class="p">}</span>                       <span class="p">}</span>

<span class="kt">void</span> <span class="nf">zaz</span><span class="p">()</span> <span class="p">{</span>            <span class="kt">void</span> <span class="n">bar</span><span class="p">()</span> <span class="p">{</span>
   <span class="c1">// code...              // code...</span>
<span class="p">}</span>                       <span class="p">}</span>

<span class="kt">void</span> <span class="nf">bar</span><span class="p">()</span> <span class="p">{</span>            <span class="kt">void</span> <span class="n">zaz</span><span class="p">()</span> <span class="p">{</span>
   <span class="c1">// code...              // code...</span>
<span class="p">}</span>                       <span class="p">}</span>
</code></pre></div></div>

<p>Version B may be <em>faster</em> than A just because <code class="highlighter-rouge">bar()</code> was moved closer
to <code class="highlighter-rouge">foo()</code> and the code of <code class="highlighter-rouge">bar()</code> gets into the cache at the moment
that <code class="highlighter-rouge">foo()</code> does the call.</p>

<p>Code layout, <a href="https://easyperf.net/blog/2018/01/18/Code_alignment_issues">code alignment</a>,
data alignment, and who knows what else may change.</p>

<p>And trust me, <a href="https://users.cs.northwestern.edu/~robby/courses/322-2013-spring/mytkowicz-wrong-data.pdf">Producing Wrong Data Without Doing Anything Obviously Wrong!</a>
is very common and almost unavoidable.</p>




    </article>
    <span class="print-footer">Quiescent Environment - March 7, 2021 - Gehn</span>
    <footer>
    <hr class="slender">
    <div class="credits">
        <span>&copy; 2021
            
            Gehn
        </span></br>
            <a style="text-decoration: none;" href="/book-of-gehn/feed.xml"><img height="16px" width="16px" src="/book-of-gehn/assets/blog-assets/rss-32px.png" /></a>
        <br>
        

    
    </div>
</footer>

  </body>
</html>
